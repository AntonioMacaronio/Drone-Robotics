{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # version 2.1.2\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as FT\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "from model import YoloV1\n",
    "from resnet_model import YoloV1_Pretrained\n",
    "from dataset import VOCDataset\n",
    "from loss import YoloLoss\n",
    "from utils import *\n",
    "\n",
    "seed = 3301 #pseudorandom seed, gets the same dataset loading\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our model\n",
    "LEARNING_RATE = 2e-5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 50\n",
    "WEIGHT_DECAY = 0    # no regularization in order for fast training\n",
    "EPOCHS = 50\n",
    "\n",
    "# Other variables for training\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "LOAD_MODEL_FNAME = \"overfit.pth.tar\"\n",
    "SAVE_MODEL_FNAME = \"yolotrained.tar\"\n",
    "IMG_DIR = \"data/images\"\n",
    "LABEL_DIR = \"data/labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell generates a validation set\n",
    "import numpy as np\n",
    "np.random.seed(3301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates the 3 datasets: train_trimmed, validation, and test\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)), \n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "# creating datasets/dataloaders\n",
    "\n",
    "train_trimmed_dataset = VOCDataset(\n",
    "    'data/10matthew.csv',\n",
    "    transform = transform, \n",
    "    img_dir = IMG_DIR,\n",
    "    label_dir = LABEL_DIR\n",
    ")\n",
    "\n",
    "train_trimmed_loader = DataLoader(\n",
    "    dataset = train_trimmed_dataset,\n",
    "    batch_size = 1,\n",
    "    num_workers= NUM_WORKERS,\n",
    "    pin_memory= PIN_MEMORY,\n",
    "    shuffle = True,\n",
    "    drop_last = False       # True for training, and since numDatapoints > batchSize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines a function to train the model on the all the datapoints in the train_loader\n",
    "def train_fn(train_loader, model, optimizer, loss_fn):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    mean_loss = []\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(loop):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE) \n",
    "        # x has shape torch.Size([batchSize, 3, 448, 448])\n",
    "        # y has shape torch.Size([batchSize, 7, 7, 30])\n",
    "        \n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        mean_loss.append(loss.item())\n",
    "        \n",
    "        # backpropogation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update progress bar\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    total_loss = sum(mean_loss)/len(mean_loss)\n",
    "    return total_loss\n",
    "\n",
    "def yololoss_validation_evaluation(loader, model, loss_fn):\n",
    "    \"\"\"Given a dataset, evaluates the model's defined yolo loss on that dataset and returns it\"\"\"\n",
    "    mean_loss = []\n",
    "    \n",
    "    model.eval()\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE) \n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        mean_loss.append(loss.item())\n",
    "    model.train() # return the model in training mode\n",
    "    \n",
    "    total_loss = sum(mean_loss)/len(mean_loss)\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop on VOC Dataset (Transfer Learning / Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE MODEL (takes 7 minutes per epoch)\n",
    "model = YoloV1_Pretrained(S = 7, B = 2, C = 20).to(DEVICE)\n",
    "model = DataParallel(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "loss_fn = YoloLoss()\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    load_checkpoint(torch.load(LOAD_MODEL_FNAME), model, optimizer)\n",
    "\n",
    "# performance tracking\n",
    "mAP_train_list = []\n",
    "mAP_valid_list = []\n",
    "avgloss_train_list = []\n",
    "avgloss_valid_list = []\n",
    "best_valid_mAP = 0.5\n",
    "\n",
    "# trains through the entire dataset once\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1} Results:\")\n",
    "    # get_bboxes puts the model in .eval() mode to evaluate and then switches it back to model.train() when finished evaluating bboxes\n",
    "    pred_boxes_train, target_boxes_train = get_bboxes(train_trimmed_loader, model, iou_threshold = 0.5, prob_threshold = 0.4)\n",
    "    pred_boxes_valid, target_boxes_valid = get_bboxes(validation_loader, model, iou_threshold = 0.5, prob_threshold = 0.4)\n",
    "    # pred_boxes (list of lists) = [[train_idx, class_prediction, prob_score, x1, y1, x2, y2],...], each list within the big list represents a bbox\n",
    "    # target_boxes = ^\n",
    "    # note: the length of these lists >= numDatapoints\n",
    "    \n",
    "    # Calculate the mAP from our evaluated bboxes\n",
    "    mAP_train = mean_average_precision(pred_boxes_train, target_boxes_train, iou_threshold=0.5, box_format=\"midpoint\")\n",
    "    mAP_valid = mean_average_precision(pred_boxes_valid, target_boxes_valid, iou_threshold=0.5, box_format=\"midpoint\")\n",
    "    mAP_train_list.append(mAP_train)\n",
    "    mAP_valid_list.append(mAP_valid)\n",
    "    print(f\"Train mAP: {mAP_train}\")\n",
    "    print(f\"Validation mAP: {mAP_valid}\")\n",
    "    \n",
    "    # Calculate the average YOLO loss from our evaluated bboxes\n",
    "    yolo_loss_train = train_fn(train_trimmed_loader, model, optimizer, loss_fn)\n",
    "    yolo_loss_valid = yololoss_validation_evaluation(validation_loader, model, loss_fn)\n",
    "    print(f\"Average training loss per image: {yolo_loss_train}\")\n",
    "    print(f\"Average validation loss per image: {yolo_loss_valid}\")\n",
    "    avgloss_train_list.append(yolo_loss_train)\n",
    "    avgloss_valid_list.append(yolo_loss_valid)\n",
    "    print()\n",
    "\n",
    "    # early stopping - once validation mAP hits .5, we start saving the model with the best validation mAP\n",
    "    if mAP_valid > best_valid_mAP:\n",
    "        best_valid_mAP = mAP_valid\n",
    "        torch.save(model, \"yolotrained.tar\")\n",
    "\n",
    "checkpoint = {\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"optimizer\": optimizer.state_dict(),\n",
    "}\n",
    "save_checkpoint(checkpoint, filename=SAVE_MODEL_FNAME) # saves the model with torch.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell saves the model\n",
    "torch.save(model, \"yolo_resnet_pretrained.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell loads the model\n",
    "tar_file_path = \"yolotrained.tar\"\n",
    "model = torch.load(tar_file_path)\n",
    "model(torch.rand(10, 3, 448, 448)) # testing if we got it :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(BATCH_SIZE, 3, 448, 448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the model on the training set and test test: (takes about 4 min)\n",
    "\n",
    "train_trimmed_loader_INORDER = DataLoader(\n",
    "    dataset = train_trimmed_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers= NUM_WORKERS,\n",
    "    pin_memory= PIN_MEMORY,\n",
    "    shuffle = False,\n",
    "    drop_last = False       # True for training, and since numDatapoints > batchSize\n",
    ")\n",
    "\n",
    "pred_boxes_train, target_boxes_train = get_bboxes(train_trimmed_loader_INORDER, model, iou_threshold = 0.5, prob_threshold = 0.4)\n",
    "pred_boxes_test, target_boxes_test = get_bboxes(test_loader, model, iou_threshold = 0.5, prob_threshold = 0.25)\n",
    "\n",
    "print(\"Final Training mAP:\", mean_average_precision(pred_boxes_train, target_boxes_train))\n",
    "print(\"Final Testing mAP:\", mean_average_precision(pred_boxes_test, target_boxes_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_voc_classes = {\n",
    "    0: 'airplane', 1: 'bicycle', 2: 'bird', 3: 'boat', 4: 'bottle',\n",
    "    5: 'bus', 6: 'car', 7: 'cat', 8: 'chair', 9: 'cow', \n",
    "    10: 'diningtable', 11: 'dog', 12: 'horse', 13: 'motorbike', 14: 'person',\n",
    "    15: 'pottedplant', 16: 'sheep', 17: 'sofa', 18: 'train', 19: 'TVmonitor',\n",
    "}\n",
    "\n",
    "classEnum_to_color = {\n",
    "    0: 'red', 1: 'blue', 2: 'green', 3: 'purple', 4: 'orange', \n",
    "    5: 'cyan', 6: 'magenta', 7: 'yellow', 8: 'brown', 9: 'lime',\n",
    "    10: 'pink', 11: 'teal', 12: 'olive', 13: 'navy', 14: 'indigo',\n",
    "    15: 'maroon', 16: 'gold', 17: 'orchid', 18: 'turquoise', 19: 'slategray'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Performance\n",
    "The following cells plot the results outputted by the model as well as their respective labels, as well as loss and mAP over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(mAP_valid_list)), [x.item() for x in mAP_valid_list], label='Validation mAP')\n",
    "plt.plot(range(len(mAP_train_list)), [x.item() for x in mAP_train_list], label='Training mAP')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch Iteration Number\")\n",
    "plt.ylabel(\"mAP (Mean Average Precision)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['utils'])\n",
    "from utils import plot_bbox_and_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Results! \n",
    "Left is the predictions by our model, the right is the labeled datapoint from out training dataset (does not include validation set datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox_and_label(\"train_trimmed.csv\", 1, pred_boxes_train, target_boxes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox_and_label(\"train_trimmed.csv\", 5, pred_boxes_train, target_boxes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox_and_label(\"train_trimmed.csv\", 10, pred_boxes_train, target_boxes_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Results! \n",
    "Left is the predictions by our model, the right is the labeled test datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox_and_label(\"test.csv\", 0, pred_boxes_test, target_boxes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox_and_label(\"test.csv\", 5, pred_boxes_test, target_boxes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox_and_label(\"test.csv\", 15, pred_boxes_test, target_boxes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox_and_label(\"test.csv\", 25, pred_boxes_test, target_boxes_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
